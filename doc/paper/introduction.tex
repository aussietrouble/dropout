\section{Introduction}



In contemporary settings for large scale statistical learning,
managing computational costs is important.
It is increasingly desirable to have learning
algorithms with ``knobs'' that enable one to lower the computational
burden in a controlled and fine-grained manner, while smoothly
regulating the statistical error.  Ideally, the tradeoff between
computation and error should be explicit and well understood theoretically.

In this paper, we propose a procedure to iteratively ``drop out''
entries in the data matrix, drawing inspiration from a recent
heuristic for training large multi-layer neural networks for image
processing \citep{Hinton:2012}.  The dropout method in deep learning is
used as a form of regularization to avoid over-fitting.  A formal
correspondence with regularization was established in \cite{Wager:2013}.
In contrast, our rationale for employing the dropout is to enable more
efficient computation of a linear model, while controlling the excess
risk that this data corruption incurs.  To achieve this we make use of recent algorithmic advances in
``subspace embedding'' techniques \citep{Clarkson:2012,Nelson:2012},
which enable fast algorithms for low rank approximation and least
squares estimation from sparse data matrices.

We develop these ideas in the setting of linear regression for massive
data, focusing on the $n\gg p$ regime, where the sample size $n$ is
large relative to the number of variables $p$.  Our first technical
result is a series of probability bounds on the error of the dropout
method for a generalized ridge regression problem.  Using these
bounds, we are able to make precise the tradeoff between computation
and risk that results when the data are sparsified to allow fast
algorithms using subspace embedding.  Both our analysis and
simulations show that the dropout method has a favorable
risk-computation tradeoff to simple subsampling of the data.

Our next contribution is to apply this thinking, and our analysis, to
the setting where many of the variables are irrelevant.  
In this case, intuitively, we wish to drop out irrelevant variables at a high rate, and drop
out important predictors at a low rate.  Clearly, if the 
irrelevant variables were known, the data could be optimally processed by
dropping out all them out completely.  The challenge is to
separate the relevant and irrelevant variables while controlling
computation.

Toward this goal, we propose a dropout version of the
alternating direction method of multipliers (ADMM) algorithm for
approximate $\ell_1$-regularized least squares (lasso) \citep{Boyd:2011}.  Each stage of
the ADMM algorithm for the lasso involves a form of ridge regression.
Leveraging our analysis of the dropout for this case, we gradually
decrease the dropout rate for variables identified as relevant in an
ADMM iteration.  As we demonstrate through both analysis and
simulation, this \textit{graduated dropout} method leads to a favorable
computational advantage over the standard ADMM procedure, with a
smooth degradation in the risk.  This advantage is maintained
when compared against ADMM run on subsampled data, to identify 
the relevant variables, followed by refitting of the reduced model.
For this procedure, statistical theory for the lasso suggests
the subsampling rate required to identify the relevant variables.

The paper proceeds as follows.  Background 
and problem formulation....Main results bounding
error.  Results on multiple iterations.  Simulations.
Discussion.

